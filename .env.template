# Azure Configurations
# Copy this file to .env and fill in your actual values

# Azure AI Content Understanding Configuration
# Your Azure AI Content Understanding API key
AZURE_CU_API_KEY=your_content_understanding_api_key_here

# Your Azure AI Content Understanding endpoint (e.g., https://your-resource-name.services.ai.azure.com/)
AZURE_CU_ENDPOINT=https://your-content-understanding-resource-name.services.ai.azure.com/

# Azure OpenAI Configuration
# Your Azure OpenAI API key
AZURE_OPENAI_API_KEY=your_api_key_here

# Your Azure OpenAI endpoint (e.g., https://your-resource-name.openai.azure.com/)
AZURE_OPENAI_ENDPOINT=https://your-resource-name.openai.azure.com/

# Azure OpenAI API version
AZURE_OPENAI_API_VERSION=2024-02-15-preview

# Your GPT-4 deployment name in Azure
AZURE_OPENAI_DEPLOYMENT_NAME=your_gpt4_deployment_name

# Processing Configuration
# Maximum tokens per text chunk sent to the LLM
MAX_TOKENS_PER_CHUNK=3000

# Temperature for LLM responses (lower = more consistent)
TEMPERATURE=0.1

# Maximum tokens in LLM response
MAX_TOKENS_RESPONSE=4000

# Retry configuration
MAX_RETRIES=3
RETRY_DELAY=2
